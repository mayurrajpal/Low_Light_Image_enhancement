{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e2vmG3aUUgEb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image, ImageOps\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def exposure_loss(x, mean_val=0.6):\n",
        "    x = tf.reduce_mean(x, axis=3, keepdims=True)\n",
        "    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n",
        "    return tf.reduce_mean(tf.square(mean - mean_val))\n",
        "\n",
        "def calculate_illumination_smoothness_loss(image_tensor):\n",
        "\n",
        "    batch_size = tf.shape(image_tensor)[0]\n",
        "    height = tf.shape(image_tensor)[1]\n",
        "    width = tf.shape(image_tensor)[2]\n",
        "\n",
        "    height_elements = (tf.shape(image_tensor)[2] - 1) * tf.shape(image_tensor)[3]\n",
        "    width_elements = tf.shape(image_tensor)[2] * (tf.shape(image_tensor)[3] - 1)\n",
        "\n",
        "    height_tv = tf.reduce_sum(tf.square(image_tensor[:, 1:, :, :] - image_tensor[:, :height - 1, :, :]))\n",
        "    width_tv = tf.reduce_sum(tf.square(image_tensor[:, :, 1:, :] - image_tensor[:, :, :width - 1, :]))\n",
        "\n",
        "    batch_size = tf.cast(batch_size, dtype=tf.float32)\n",
        "    height_elements = tf.cast(height_elements, dtype=tf.float32)\n",
        "    width_elements = tf.cast(width_elements, dtype=tf.float32)\n",
        "\n",
        "    return 2 * (height_tv / height_elements + width_tv / width_elements) / batch_size\n",
        "\n",
        "\n",
        "def compute_color_consistency_loss(image):\n",
        "\n",
        "    mean_values = tf.reduce_mean(image, axis=(1, 2), keepdims=True)\n",
        "    red_mean, green_mean, blue_mean = mean_values[:, :, :, 0], mean_values[:, :, :, 1], mean_values[:, :, :, 2]\n",
        "\n",
        "    diff_red_green = tf.square(red_mean - green_mean)\n",
        "    diff_red_blue = tf.square(red_mean - blue_mean)\n",
        "    diff_green_blue = tf.square(blue_mean - green_mean)\n",
        "\n",
        "    return tf.sqrt(diff_red_green + diff_red_blue + diff_green_blue)\n",
        "\n",
        "\n",
        "def build_custom_dce_net():\n",
        "\n",
        "    input_img = keras.Input(shape=[None, None, 3])\n",
        "\n",
        "    conv1 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(input_img)\n",
        "    conv2 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(conv1)\n",
        "    conv3 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(conv2)\n",
        "    conv4 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(conv3)\n",
        "\n",
        "    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n",
        "    conv5 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(int_con1)\n",
        "    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n",
        "    conv6 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(int_con2)\n",
        "    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n",
        "\n",
        "    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(int_con3)\n",
        "\n",
        "    model = keras.Model(inputs=input_img, outputs=x_r)\n",
        "    return model\n",
        "\n",
        "class ConsistencyLoss(keras.losses.Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ConsistencyLoss, self).__init__(reduction=\"none\")\n",
        "\n",
        "        self.kernel_left = tf.constant(\n",
        "            [[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "        self.kernel_right = tf.constant(\n",
        "            [[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "        self.kernel_up = tf.constant(\n",
        "            [[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "        self.kernel_down = tf.constant(\n",
        "            [[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def call(self, true_values, predicted_values):\n",
        "\n",
        "        mean_true = tf.reduce_mean(true_values, axis=3, keepdims=True)\n",
        "        mean_predicted = tf.reduce_mean(predicted_values, axis=3, keepdims=True)\n",
        "\n",
        "\n",
        "        pooled_true = tf.nn.avg_pool2d(\n",
        "            mean_true, ksize=4, strides=4, padding=\"VALID\"\n",
        "        )\n",
        "        pooled_predicted = tf.nn.avg_pool2d(\n",
        "            mean_predicted, ksize=4, strides=4, padding=\"VALID\"\n",
        "        )\n",
        "\n",
        "        grad_true_left = tf.nn.conv2d(\n",
        "            pooled_true, self.kernel_left, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        grad_true_right = tf.nn.conv2d(\n",
        "            pooled_true, self.kernel_right, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        grad_true_up = tf.nn.conv2d(\n",
        "            pooled_true, self.kernel_up, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        grad_true_down = tf.nn.conv2d(\n",
        "            pooled_true, self.kernel_down, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "\n",
        "        grad_pred_left = tf.nn.conv2d(\n",
        "            pooled_predicted, self.kernel_left, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        grad_pred_right = tf.nn.conv2d(\n",
        "            pooled_predicted, self.kernel_right, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        grad_pred_up = tf.nn.conv2d(\n",
        "            pooled_predicted, self.kernel_up, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "        grad_pred_down = tf.nn.conv2d(\n",
        "            pooled_predicted, self.kernel_down, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
        "        )\n",
        "\n",
        "        diff_left = tf.square(grad_true_left - grad_pred_left)\n",
        "        diff_right = tf.square(grad_true_right - grad_pred_right)\n",
        "        diff_up = tf.square(grad_true_up - grad_pred_up)\n",
        "        diff_down = tf.square(grad_true_down - grad_pred_down)\n",
        "\n",
        "        return diff_left + diff_right + diff_up + diff_down\n",
        "\n",
        "class ZeroDCE(keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ZeroDCE, self).__init__(**kwargs)\n",
        "        self.dce_model = build_custom_dce_net()\n",
        "\n",
        "    def compile(self, learning_rate, **kwargs):\n",
        "        super(ZeroDCE, self).compile(**kwargs)\n",
        "        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.constancy_loss = ConsistencyLoss(reduction=\"none\")\n",
        "\n",
        "    def get_enhanced_image(self, data, output):\n",
        "        r1 = output[:, :, :, :3]\n",
        "        r2 = output[:, :, :, 3:6]\n",
        "        r3 = output[:, :, :, 6:9]\n",
        "        r4 = output[:, :, :, 9:12]\n",
        "        r5 = output[:, :, :, 12:15]\n",
        "        r6 = output[:, :, :, 15:18]\n",
        "        r7 = output[:, :, :, 18:21]\n",
        "        r8 = output[:, :, :, 21:24]\n",
        "        x = data + r1 * (tf.square(data) - data)\n",
        "        x = x + r2 * (tf.square(x) - x)\n",
        "        x = x + r3 * (tf.square(x) - x)\n",
        "        enhanced_image = x + r4 * (tf.square(x) - x)\n",
        "        x = enhanced_image + r5 * (tf.square(enhanced_image) - enhanced_image)\n",
        "        x = x + r6 * (tf.square(x) - x)\n",
        "        x = x + r7 * (tf.square(x) - x)\n",
        "        enhanced_image = x + r8 * (tf.square(x) - x)\n",
        "        return enhanced_image\n",
        "\n",
        "    def call(self, data):\n",
        "        dce_net_output = self.dce_model(data)\n",
        "        return self.get_enhanced_image(data, dce_net_output)\n",
        "\n",
        "    def compute_losses(self, data, output):\n",
        "        enhanced_image = self.get_enhanced_image(data, output)\n",
        "        loss_illumination = 200 * calculate_illumination_smoothness_loss(output)\n",
        "        loss_spatial_constancy = tf.reduce_mean(\n",
        "            self.constancy_loss(enhanced_image, data)\n",
        "        )\n",
        "        loss_color_constancy = 5 * tf.reduce_mean(compute_color_consistency_loss(enhanced_image))\n",
        "        loss_exposure = 10 * tf.reduce_mean(exposure_loss(enhanced_image))\n",
        "        total_loss = (\n",
        "            loss_illumination\n",
        "            + loss_spatial_constancy\n",
        "            + loss_color_constancy\n",
        "            + loss_exposure\n",
        "        )\n",
        "        return {\n",
        "            \"total_loss\": total_loss,\n",
        "            \"illumination_smoothness_loss\": loss_illumination,\n",
        "            \"spatial_constancy_loss\": loss_spatial_constancy,\n",
        "            \"color_constancy_loss\": loss_color_constancy,\n",
        "            \"exposure_loss\": loss_exposure,\n",
        "        }\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self.dce_model(data)\n",
        "            losses = self.compute_losses(data, output)\n",
        "        gradients = tape.gradient(\n",
        "            losses[\"total_loss\"], self.dce_model.trainable_weights\n",
        "        )\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n",
        "        return losses\n",
        "\n",
        "    def test_step(self, data):\n",
        "        output = self.dce_model(data)\n",
        "        return self.compute_losses(data, output)\n",
        "\n",
        "    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n",
        "        \"\"\"While saving the weights, we simply save the weights of the DCE-Net\"\"\"\n",
        "        self.dce_model.save_weights(\n",
        "            filepath, overwrite=overwrite, save_format=save_format, options=options\n",
        "        )\n",
        "\n",
        "    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n",
        "        \"\"\"While loading the weights, we simply load the weights of the DCE-Net\"\"\"\n",
        "        self.dce_model.load_weights(\n",
        "            filepath=filepath,\n",
        "            by_name=by_name,\n",
        "            skip_mismatch=skip_mismatch,\n",
        "            options=options,\n",
        "        )\n",
        "\n",
        "def infer(original_image):\n",
        "    image = keras.preprocessing.image.img_to_array(original_image)\n",
        "    image = image.astype(\"float32\") / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    output_image = zero_dce_model(image)\n",
        "    output_image = tf.cast((output_image[0, :, :, :] * 255), dtype=np.uint8)\n",
        "    output_image = Image.fromarray(output_image.numpy())\n",
        "    return output_image\n",
        "\n",
        "zero_dce_model = ZeroDCE()\n",
        "#os.chdir('/content/drive/MyDrive')\n",
        "current_directory = os.getcwd()\n",
        "weights=r'zerodcemodel.h5'\n",
        "model_path=os.path.join(current_directory,weights)\n",
        "zero_dce_model.load_weights(model_path)\n",
        "\n",
        "test_imgs = sorted(glob('./test/low/*'))\n",
        "save_dir = r'test/predicted'\n",
        "current_directory = os.getcwd()\n",
        "path = os.path.join(current_directory,save_dir)\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for val_image_file in test_imgs:\n",
        "\n",
        "    original_image = Image.open(val_image_file)\n",
        "    enhanced_image = infer(original_image)\n",
        "\n",
        "    original_image_np = np.array(original_image)\n",
        "    enhanced_image_np = np.array(enhanced_image)\n",
        "\n",
        "    file_name = os.path.basename(val_image_file)\n",
        "    output_path = os.path.join(path, 'enhanced_' + file_name)\n",
        "    enhanced_image.save(output_path)\n",
        "\n",
        "    plt.imshow(enhanced_image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    }
  ]
}